\todo{Develop arguments that the responsibility formalism might actually be put to good use, as per \cref{sec:intro}}
section{Proposed Approach}\label{sec:proposed_approach}

\subsection{C\&F\@ Close, but no cigar}
As it turns out, cognitive computational trust models that already exist are almost but not quite appropriate for modelling responsibility, too. The C\&F trust model requires only four main ingredients to formulate a cognitive trust model:

\begin{enumerate}
    \item \emph{x}, a truster
    \item \emph{y}, a subject of trust
    \item \emph{g}, a goal of \emph{x}
    \item \emph{\safealpha}, an action of \emph{y}
\end{enumerate}\par

This model gets us close to where we need to be to model responsibility; like responsibility modelling often does, it assumes two agents. There also exists some goal which can be met, which --- to use C\&F terminology --- is \emph{delegated} by \emph{x} to \emph{y}. \emph{Y} can achieve this goal through some action, \emph{\safealpha}. So far, all of this forms the beginning of a foundation for cognitive responsibility; what turns delegation of a task into the consignment of responsibility is that of obligation, and the understanding of obligation. \par

It is evident that trust and responsibility models are, even in the human-like cognitive approach, very similar. However, crucial differences mean that we cannot directly apply C\&F theory to the idea of computational responsibility. \par

Therefore, I propose that research must be carried out to ascertain whether C\&F can, as a model, be adapted simply to account for an agent's responsibility. In addition, research must be carried out to implement this model in a BDI logic agent, enabling the evaluation of the new model's success. \todo{WE SHOULD BE ABLE TO ADAPT~\cite{HubnerFromTrust} TO IMPLEMENT OUR NEW COGNITIVE RESPONSIBILITY MODEL IN A BELIEF, DESIRE, INTENTION AGENT MODEL\@. THEY DO A DIRECT APPLICATION OF C\&F TO BDI, WE SHOULD TOO.}


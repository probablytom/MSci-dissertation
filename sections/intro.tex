\section{Introduction}\label{sec:intro}

Computational Responsibility is a field with little to no existing literature. Rather than a focus on \emph{responsibility}, researchers have so far tackled a variety of other social topics through computational formalisation:

\begin{itemize}
    \item Marsh's seminal work on Trust\cite{Marsh1994FormalisingConcept}
    
    \item Stricter formal definitions on Trust, from a cognitive standpoint\cite{CastelfranchiSocialApproach}
    
    \item Some responsibility modelling, from a logical formalisation\cite{Simpson2015FormalisingAnalysis}\todo{Finish reading this!}
    
    \item Some work on reputation~\cite{Chandrasekaran2011ASystems}

    \item Models of computational comfort models\cite{Marsh2011}.
    
\end{itemize}

%something something there's a gap here where nobody's applied machine learning to the problem for teaching artificial agents about the social concept of responsibility
While there is no direct literature on responsibility formalisms, then, we can see that there exists a wealth of literature for a responsibility formalism to be inspired by.\par

A responsibility formalism is useful in the same ways that formalisms of human traits such as reputation and trust might be; however, a responsibility formalism has the potential to have impacts in areas trust and reputation might not. For example, imbuing an intelligent agent with a sense of responsibility might provide it a greater degree of corrigibility\cite{corrigibility}. An agent overseeing network security which understands its responsibilities within a much larger security system might better prioritise its duties when confronted with an unusual situation. Computational responsibility frameworks might help better model the emergent phenomena in sociotechnical systems, combine with traits like trust and comfort to make a more anthropomorphic device for better HCI, or perhaps help predict human actions in large computational models of human actors. We will explore some of these practical applications in \cref{sec:proposed_approach}.\par

However, it is certain that a uses for these formalisms present themselves at every turn.\todo{Write something concrete here regarding fields it might be applicable in, like decision theory or AI safety or network security or socitechnical modelling}\par

\subsection{An early rebuttal of some common criticisms}

One easy criticism to make of these anthropomorphic formalisms is the argument that, say, a trust formalism doesn't represent ``true'' trust. To address this point early, a responsibility formalism such as the one proposed need not be an entirely human-like representation of responsibility for every definition. Rather, there is a utility in an agent giving the \emph{appearance} of responsibility. (If one follows the deterministic school of thought, there is also an argument that there is no difference\cite{determinism_in_brief}.) Whether one considers it ``true'' responsibility should arguably be secondary to whether responsibility-like traits are useful to have computational frameworks for; we will see that these traits are indeed useful, and so that the criticism is moot.\par

\subsection{Terminology}\label{subsec:terminology}
\todo{Fill with terminology, in a style similar to honours dissertation}
